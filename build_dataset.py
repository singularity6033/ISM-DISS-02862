# import the necessary packages
from pycocotools.coco import COCO
from utils.iou import compute_iou
from utils import config
from bs4 import BeautifulSoup
from imutils import paths
import numpy as np
import re
import cv2
import os

# grab all image paths in the input images directory
imagePaths = list(paths.list_images(config.ORIG_IMAGES))

# using cocoAPI to load coco annotation information
coco = COCO(config.ORIG_ANNOTS)
# load COCO categories and super categories
cats = coco.loadCats(coco.getCatIds())
catIds = [cat['id'] for cat in cats]
# initialize the total number of label class filename we have
# saved to disk so far
label_counter = np.zeros((len(cats), 1), dtype=int)
# loop over the image paths
for (i, imagePath) in enumerate(imagePaths):
    # show a progress report
    print("[INFO] processing image {}/{}...".format(i + 1, len(imagePaths)))
    # extract the filename from the file path and use it to derive
    # the path to the XML annotation file
    filename = imagePath.split(os.path.sep)[-1]
    filename = filename[:filename.rfind(".")]
    img_id = int(filename.lstrip('0'))
    annIds = coco.getAnnIds(imgIds=img_id, iscrowd=None)
    annInfos = coco.loadAnns(annIds)
    # initialize our list of ground-truth bounding boxes
    gtBoxes = []
    # coco bounding box format: (x - top left, y - top left, width, height)
    # loop over all 'object' elements
    for annInfo in annInfos:
        # extract the label and bounding box coordinates
        label_id = annInfo['category_id']
        xMin, yMin, bw, bh = annInfo['bbox']
        xMax = xMin + bw
        yMax = yMin + bh
        # update our list of ground-truth bounding boxes
        gtBoxes.append((xMin, yMin, xMax, yMax, label_id))
    # load the input image from disk
    image = cv2.imread(imagePath)
    # run selective search on the image and initialize our list of
    # proposed boxes
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    proposedRects = []
    # loop over the rectangles generated by selective search
    for (x, y, w, h) in rects:
        # convert our bounding boxes from (x, y, w, h) to (startX, startY, startX, endY)
        proposedRects.append((x, y, x + w, y + h))
    # initialize counters used to count the number of positive
    positiveROIs = 0

    # loop over the maximum number of region proposals
    for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
        # unpack the proposed rectangle bounding box
        (propStartX, propStartY, propEndX, propEndY) = proposedRect
        # loop over the ground-truth bounding boxes
        for gtBox in gtBoxes:
            # compute the intersection over union between the two
            # boxes and unpack the ground-truth bounding box
            iou = compute_iou(gtBox[:-1], proposedRect)
            (gtStartX, gtStartY, gtEndX, gtEndY, label_id) = gtBox
            # initialize the ROI and output path
            roi = None
            outputPath = None
            # check to see if the IOU is greater than 70% *and* that
            # we have not hit our positive count limit
            if iou > 0.8 and positiveROIs <= config.MAX_POSITIVE:
                # extract the ROI and then derive the output path to
                # the positive instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                cat = cats[catIds.index(label_id)]['name']
                if cat is not "train":
                    break
                print('train')
                filename = "{}.png".format(label_counter[catIds.index(label_id), 0])
                outputPath = os.path.sep.join([config.DATASET_BASE_PATH, cat])
                if not os.path.exists(outputPath):
                    os.makedirs(outputPath)
                filePath = os.path.sep.join([outputPath, filename])
                # increment the positive counters
                positiveROIs += 1
                label_counter[catIds.index(label_id), 0] += 1
                # check to see if both the ROI and output path are valid
                if roi is not None and filePath is not None:
                    # resize the ROI to the input dimensions of the CNN
                    # that we'll be fine-tuning, then write the ROI to disk
                    roi = cv2.resize(roi, config.INPUT_DIMS, interpolation=cv2.INTER_CUBIC)
                    cv2.imwrite(filePath, roi)
# import the necessary packages
from pycocotools.coco import COCO
from utils.iou import compute_iou
from utils import config
from bs4 import BeautifulSoup
from imutils import paths
import numpy as np
import re
import cv2
import os

# grab all image paths in the input images directory
imagePaths = list(paths.list_images(config.ORIG_IMAGES))

# using cocoAPI to load coco annotation information
coco = COCO(config.ORIG_ANNOTS)
# load COCO categories and super categories
cats = coco.loadCats(coco.getCatIds())
catIds = [cat['id'] for cat in cats]
# initialize the total number of label class filename we have
# saved to disk so far
label_counter = np.zeros((len(cats), 1), dtype=int)
# loop over the image paths
for (i, imagePath) in enumerate(imagePaths):
    # show a progress report
    print("[INFO] processing image {}/{}...".format(i + 1, len(imagePaths)))
    # extract the filename from the file path and use it to derive
    # the path to the XML annotation file
    filename = imagePath.split(os.path.sep)[-1]
    filename = filename[:filename.rfind(".")]
    img_id = int(filename.lstrip('0'))
    annIds = coco.getAnnIds(imgIds=img_id, iscrowd=None)
    annInfos = coco.loadAnns(annIds)
    # initialize our list of ground-truth bounding boxes
    gtBoxes = []
    # coco bounding box format: (x - top left, y - top left, width, height)
    # loop over all 'object' elements
    for annInfo in annInfos:
        # extract the label and bounding box coordinates
        label_id = annInfo['category_id']
        xMin, yMin, bw, bh = annInfo['bbox']
        xMax = xMin + bw
        yMax = yMin + bh
        # update our list of ground-truth bounding boxes
        gtBoxes.append((xMin, yMin, xMax, yMax, label_id))
    # load the input image from disk
    image = cv2.imread(imagePath)
    # run selective search on the image and initialize our list of
    # proposed boxes
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    proposedRects = []
    # loop over the rectangles generated by selective search
    for (x, y, w, h) in rects:
        # convert our bounding boxes from (x, y, w, h) to (startX, startY, startX, endY)
        proposedRects.append((x, y, x + w, y + h))
    # initialize counters used to count the number of positive
    positiveROIs = 0

    # loop over the maximum number of region proposals
    for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
        # unpack the proposed rectangle bounding box
        (propStartX, propStartY, propEndX, propEndY) = proposedRect
        # loop over the ground-truth bounding boxes
        for gtBox in gtBoxes:
            # compute the intersection over union between the two
            # boxes and unpack the ground-truth bounding box
            iou = compute_iou(gtBox[:-1], proposedRect)
            (gtStartX, gtStartY, gtEndX, gtEndY, label_id) = gtBox
            # initialize the ROI and output path
            roi = None
            outputPath = None
            # check to see if the IOU is greater than 70% *and* that
            # we have not hit our positive count limit
            if iou > 0.8 and positiveROIs <= config.MAX_POSITIVE:
                # extract the ROI and then derive the output path to
                # the positive instance
                roi = image[propStartY:propEndY, propStartX:propEndX]
                cat = cats[catIds.index(label_id)]['name']
                if cat is not "train":
                    break
                print('train')
                filename = "{}.png".format(label_counter[catIds.index(label_id), 0])
                outputPath = os.path.sep.join([config.DATASET_BASE_PATH, cat])
                if not os.path.exists(outputPath):
                    os.makedirs(outputPath)
                filePath = os.path.sep.join([outputPath, filename])
                # increment the positive counters
                positiveROIs += 1
                label_counter[catIds.index(label_id), 0] += 1
                # check to see if both the ROI and output path are valid
                if roi is not None and filePath is not None:
                    # resize the ROI to the input dimensions of the CNN
                    # that we'll be fine-tuning, then write the ROI to disk
                    roi = cv2.resize(roi, config.INPUT_DIMS, interpolation=cv2.INTER_CUBIC)
                    cv2.imwrite(filePath, roi)
