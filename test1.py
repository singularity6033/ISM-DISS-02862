# import the necessary packages
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.python.keras.models import load_model
from utils.iou import compute_iou
from utils.ap import compute_ap
from utils import config
import matplotlib.pyplot as plt
from pycocotools.coco import COCO
from imutils import paths
import numpy as np
import cv2
import pickle
import os


# load label binarizer
lb = pickle.loads(open(config.ENCODER_PATH, "rb").read())
# initialize the initial learning rate, number of epochs to train for and batch size
INIT_LR = 1e-4
EPOCHS = 5
BS = 32
model = load_model(config.MODEL_PATH)
print("[INFO] evaluating object detector...")
# make predictions on the testing set and calculate the AP and mAP matrices
print("[INFO] loading testing images...")
# grab all image paths in the test images directory
TestImagePaths = list(paths.list_images(config.TEST_IMAGES))
# using cocoAPI to load coco annotation information
coco = COCO(config.TEST_ANNOTS)
# load COCO categories and super categories
cats = coco.loadCats(coco.getCatIds())
catIds = [cat['id'] for cat in cats]

NUM_CLASS = len(lb.classes_)
# MIN_IOU: minimum threshold of iou to determine whether a roi is TP or NP
MIN_IOU = 0.75
# AP: the area under the precision-recall curve, one class one AP
AP = np.zeros(NUM_CLASS)
# TP_FP: list of TP(1) and NP(0)
TP_FP = [[] for i in range(NUM_CLASS)]
# TP_FN: TP + FN = total num of ground-truth of each class
TP_FN = np.zeros(NUM_CLASS)
# Precision: TP / (TP + FP)
Precision = [[] for i in range(NUM_CLASS)]
# Recall: TP / (TP + FN)
Recall = [[] for i in range(NUM_CLASS)]

# loop over testing image paths
for (i, TestImagePath) in enumerate(TestImagePaths[:200]):
    # show a progress report
    print("[INFO] evaluating testing image {}/{}...".format(i + 1, len(TestImagePaths[:200])))
    # extract the filename from the file path and use it to derive
    # the path to the XML annotation file
    filename = TestImagePath.split(os.path.sep)[-1]
    filename = filename[:filename.rfind(".")]
    img_id = int(filename.lstrip('0'))
    annIds = coco.getAnnIds(imgIds=img_id, iscrowd=None)
    annInfos = coco.loadAnns(annIds)
    # initialize our list of ground-truth bounding boxes
    gtBoxes = []
    # coco bounding box format: (x - top left, y - top left, width, height)
    # loop over all ground-truth 'object' elements in testing images
    for annInfo in annInfos:
        # extract the label and bounding box coordinates
        label_id = annInfo['category_id']
        cat = cats[catIds.index(label_id)]['name']
        # record num of ground-truth in each class
        idx_gt = np.where(lb.classes_ == cat)
        TP_FN[idx_gt] += 1
        xMin, yMin, bw, bh = annInfo['bbox']
        xMax = xMin + bw
        yMax = yMin + bh
        # update our list of ground-truth bounding boxes
        gtBoxes.append((xMin, yMin, xMax, yMax, label_id))
    # load the input image from disk
    image = cv2.imread(TestImagePath)
    # run selective search on the image and initialize our list of
    # proposed boxes
    ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    ss.setBaseImage(image)
    ss.switchToSelectiveSearchFast()
    rects = ss.process()
    proposedRoi = []
    proposedBoxes = []
    # loop over the rectangles generated by selective search
    for (x, y, w, h) in rects:
        roi = image[y:y + h, x:x + w]
        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
        roi = cv2.resize(roi, config.INPUT_DIMS, interpolation=cv2.INTER_CUBIC)
        # further preprocess the ROI
        roi = img_to_array(roi)
        roi = preprocess_input(roi)
        # update our proposedRoi and proposedBoxes lists
        proposedRoi.append(roi)
        proposedBoxes.append((x, y, x + w, y + h))
    # initialize counters used to count the number of positive
    positiveROIs = 0
    proposedRoi = np.array(proposedRoi, dtype="float32")
    label_proba = model.predict(proposedRoi)
    proposedLabels = lb.classes_[np.argmax(label_proba, axis=1)]
    # loop over the maximum number of region proposals
    for proposedId, proposedLabel in enumerate(proposedLabels[:config.MAX_PROPOSALS]):
        # loop over the ground-truth bounding boxes
        for gtBox in gtBoxes:
            # compute the intersection over union (iou) between each proposed boxes
            # and the ground-truth bounding box to decide whether it is TP or FP
            iou = compute_iou(gtBox[:-1], proposedBoxes[proposedId])
            (gtStartX, gtStartY, gtEndX, gtEndY, label_id) = gtBox
            cat = cats[catIds.index(label_id)]['name']
            # check to see if the IOU is greater than 80%(P)
            if cat == proposedLabel:
                if iou > MIN_IOU:
                    TP_FP[list(lb.classes_).index(proposedLabel)].append(1)
                else:
                    TP_FP[list(lb.classes_).index(proposedLabel)].append(0)
for j in range(len(TP_FP)):
    for k in range(len(TP_FP[j])):
        Precision[j].append(sum(TP_FP[j][0:k]) / (len(TP_FP[j][0:k]) + 1))
        Recall[j].append(sum(TP_FP[j][0:k]) / TP_FN[j])
    AP[j] = compute_ap(Precision[j], Recall[j])
mAP = np.mean(AP, axis=0)

# plot AP and print mAP
plt.style.use("ggplot")
plt.figure()
plt.title("Average Precision (with IoU threshold = " + str(MIN_IOU) + ")")
plt.plot(lb.classes_[:80], AP)
plt.xticks(rotation=300)
plt.xlabel("Class Labels")
plt.ylabel("AP")
plotPath = os.path.sep.join([config.PLOTS_PATH, "coco_AP.png"])
plt.savefig(plotPath)
plt.close()
print("COCO's mAP is equal to " + str(mAP) + " (with IoU threshold = " + str(MIN_IOU) + ")")
